{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b69334b",
   "metadata": {},
   "source": [
    "# Este cuaderno genera muestras de entrenamiento y validación para modelos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f9f71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio actual: C:\\Users\\juanm\\Dropbox\\Vías clinicas diabetes\n"
     ]
    }
   ],
   "source": [
    "## Liberías necesarias \n",
    "import os\n",
    "import re\n",
    "import socket \n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Configuración de rutas\n",
    "print('Directorio actual: '+ os.getcwd())\n",
    "\n",
    "created_path = './../created_data/'\n",
    "temp_path = './../created_data/'\n",
    "\n",
    "C:\\Users\\juanm\\Dropbox\\JP_files\\UR\\Vías clinicas diabetes\\Codigo\\ml_models\\r_y_r\\ml_models_github_repo\\created_data\\ml_databases\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e45cd01",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead9e6cc",
   "metadata": {},
   "source": [
    "#### Eliminación de NA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e132cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miss_val_del(data_mat,\n",
    "                 na_drop, \n",
    "                 tgt_label_var_name = None):\n",
    "    if na_drop == \"all\": # En caso de querer quitar todos \n",
    "        data_mat = data_mat.dropna(axis = 0)\n",
    "        \n",
    "    elif na_drop == \"label\": # En caso de querer quitar solo los del label \n",
    "        data_mat = data_mat.loc[~data_mat.loc[:, tgt_label_var_name].isnull(), :]\n",
    "        \n",
    "    return data_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df27357",
   "metadata": {},
   "source": [
    "#### Resumen grupos de medicamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e74647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meds_groups_summary(data_mat, vars_to_keep):\n",
    "    meds_groups = ['analgesicos',\n",
    "                   'antiacidos',\n",
    "                   'anticoagulantes',\n",
    "                   'antihipertensivos', \n",
    "                   'antidepresivos', \n",
    "                   'hipoglicemiantes',\n",
    "                   'hipolipemiantes',\n",
    "                   'medicion',\n",
    "                   'terapia proteccion']\n",
    "    \n",
    "    meds_to_keep = list()\n",
    "    for i in np.arange(0, len(meds_groups)):\n",
    "        if data_mat.filter(like = meds_groups[i]).shape[1] == 0:\n",
    "            pass\n",
    "        elif data_mat.filter(like = meds_groups[i]).shape[1] == 1:\n",
    "            meds_to_keep.append(meds_groups[i])\n",
    "        elif data_mat.filter(like = meds_groups[i]).shape[1] > 1:\n",
    "            data_mat.loc[:, meds_groups[i]] = np.where(data_mat.filter(like = meds_groups[i]).sum(axis = 1 )>0, 1, 0)\n",
    "            meds_to_keep.append(meds_groups[i])\n",
    "\n",
    "    data_mat = data_mat.loc[:, vars_to_keep+meds_to_keep]\n",
    "\n",
    "    return data_mat, meds_to_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d222d2fe",
   "metadata": {},
   "source": [
    "#### Eliminación de variables poco representativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "840541c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vars_drop(data_mat,\n",
    "              vars_to_ignore,\n",
    "              hemog_drop, \n",
    "              tolerance):\n",
    "    vars_to_check = set(data_mat.columns).difference(set(vars_to_ignore))\n",
    "    var_freq = data_mat.loc[:, vars_to_check].mean().to_frame().reset_index()\n",
    "    vars_to_drop = var_freq[var_freq[0]<tolerance].loc[:, 'index'].values\n",
    "    data_mat = data_mat.drop(vars_to_drop, axis = 1)\n",
    "    if hemog_drop == True: \n",
    "        data_mat = data_mat.drop(['HbA1c'], axis = 1)\n",
    "    return data_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdbd26c",
   "metadata": {},
   "source": [
    "#### Normalización de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8526d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vars_normalize(data_mat, \n",
    "                   vars_to_normalize, \n",
    "                   tgt_cat, \n",
    "                   tgt_year):\n",
    "    ## DataFrame vacío para llenar con la información de medias y desv. est. \n",
    "    stats_df = pd.DataFrame()\n",
    "    if vars_to_normalize != None: \n",
    "        try: \n",
    "            for col in vars_to_normalize:\n",
    "                mean = data_mat[col].mean()\n",
    "                sd = data_mat[col].std()\n",
    "                data_mat.loc[:, col] = (data_mat[col] - mean) /sd\n",
    "                stats_df.loc[col, ['mean', 'sd', 'cat_levels', 'years']] = [mean, sd, tgt_cat, tgt_year]\n",
    "        except:\n",
    "            print(\"Error: Issues normalizing the variables.\")\n",
    "    return data_mat, stats_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b17151b",
   "metadata": {},
   "source": [
    "#### Selección de variables tipo tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d84a6c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_var_selector(data_mat, tag_type):\n",
    "    data_mat = pd.concat([data_mat.drop(data_mat.filter(like ='tag').columns,\n",
    "                                        axis = 1),\n",
    "                          data_mat.filter(like  = 'tag_'+tag_type)],\n",
    "                         axis = 1)\n",
    "    return data_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff55d74",
   "metadata": {},
   "source": [
    "#### De tgt_label a comorbilidades y metas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4570eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Función para convertir las etiquetas a binarias\n",
    "def labels_transform(data_mat):\n",
    "    \n",
    "    ## Modificando la columna de etiquetas para generar dos nuevas columnas\n",
    "    data_mat.loc[:, 'comorbilidades'] = np.where(data_mat.loc[:, 'tgt_label']>2, 1, 0)\n",
    "    data_mat.loc[(data_mat['tgt_label'] == 2) | (data_mat['tgt_label'] == 4), 'fuera_metas'] = 1\n",
    "    data_mat.loc[:, 'fuera_metas'].fillna(0, inplace = True)\n",
    "    warnings.filterwarnings('ignore')\n",
    "    data_mat.loc[:, 'fuera_metas'] = data_mat.loc[:, 'fuera_metas'].astype(int)\n",
    "\n",
    "    return data_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfa0155",
   "metadata": {},
   "source": [
    "#### Partición en training y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f0be4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Función para particionar y exportar los datos\n",
    "def db_partitioning(data_mat,\n",
    "                    base_label,\n",
    "                    train_proportion):\n",
    "    \n",
    "    ## Seleccionando el label de referencia \n",
    "    tgt_data = data_mat[data_mat['base_label'] == base_label]\n",
    "\n",
    "    ## Particionando la base entre entrenamiento y validación \n",
    "    train, test = train_test_split(tgt_data, \n",
    "                                   train_size = train_proportion,\n",
    "                                   random_state = base_label, \n",
    "                                   stratify = tgt_data['tgt_label']) ## Stratify the sample \n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94fd28",
   "metadata": {},
   "source": [
    "### Pre-procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964435c2",
   "metadata": {},
   "source": [
    "#### Parámetros estáticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae4324bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juanm\\AppData\\Local\\Temp\\ipykernel_15088\\1274191185.py:2: DtypeWarning: Columns (90) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  example_db = pd.read_csv(created_path+'ml_databases\\\\4_cat\\\\db_transitions_1_years.csv')\n"
     ]
    }
   ],
   "source": [
    "## Cargando una base ejemplo para recuperar columnas \n",
    "example_db = pd.read_csv(created_path+'ml_databases\\\\4_cat\\\\db_transitions_1_years.csv')\n",
    "\n",
    "# Parámetros estáticos\n",
    "baseline_state_var = \"base_label\"\n",
    "label_var_name = 'tgt_label'\n",
    "vars_to_norm = ['edad', 'peso', 'talla', 'imc', 'microalbuminuria', 'Colesterol_total',\n",
    "                'Colesterol_HDL', 'Colesterol_LDL', 'TFG', #'frec_respiratoria', 'frec_cardiaca', \n",
    "                'ta_sistolica', 'ta_diastolica', 'super_corporal', 'per_abdominal', 'creatinina']\n",
    "\n",
    "comorb_vars = ['infarto',\n",
    "               'insuficiencia_cardiaca_congestiva',\n",
    "               'enf_vasc_periferica', 'enf_cerebrov',\n",
    "               'retinopatia',\n",
    "               'arritmia', \n",
    "               'enf_pulmonar', 'ERC_high']+['ERC{}'.format(x) for x in range(1, 6)]\n",
    "\n",
    "remision_vars = ['oftalmologia', 'nutricion', 'trabajo_social', 'psicologia']\n",
    "\n",
    "adh_vars = list(example_db.filter(like = 'adhiere').columns)\n",
    "tag_vars = list(example_db.filter(like = 'tag').columns)\n",
    "\n",
    "vars_to_keep = ['KeyAnonimo', \n",
    "                'year', \n",
    "                baseline_state_var,\n",
    "                label_var_name, \n",
    "                'femenino', \n",
    "                #'creatinina', \n",
    "                #'creatinina_1',\n",
    "                #'creatinina_2',\n",
    "                #'creatinina_cat',\n",
    "                'creatinina_missing']+vars_to_norm+comorb_vars+remision_vars+adh_vars+tag_vars\n",
    "\n",
    "vars_to_ignore = ['KeyAnonimo', \n",
    "                  'year',\n",
    "                  'base_label', \n",
    "                  'ERC_high', \n",
    "                  'adhiere_colesterol', \n",
    "                  'tobaco_tag_max', \n",
    "                  'hipolipemiantes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee24ea6",
   "metadata": {},
   "source": [
    "#### Ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cd4b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lista vacía para llenar con df's de estadísticas pre-normalización\n",
    "all_stats_dfs = []\n",
    "\n",
    "## Iterando entre los años\n",
    "tgt_cat = 4\n",
    "for tgt_year in [1, 2]:\n",
    "\n",
    "    ## Cargando la base de datos\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    ml_data = pd.read_csv(created_path+\"ml_databases\\\\{}_cat\\\\db_transitions_{}_years.csv\".format(tgt_cat, tgt_year))\n",
    "\n",
    "    ## Resumiendo los grupos de medicamentos\n",
    "    ml_data, kept_meds = meds_groups_summary(data_mat = ml_data,\n",
    "                                             vars_to_keep = vars_to_keep)\n",
    "\n",
    "    ## Eliminando variables poco representativas\n",
    "    ml_data = vars_drop(data_mat = ml_data, \n",
    "                        vars_to_ignore = vars_to_ignore,\n",
    "                        hemog_drop = False, \n",
    "                        tolerance = 0.1)\n",
    "\n",
    "    ## Eliminando variables con muchos missing values o innecesarias\n",
    "    ml_data.drop([#'creatinina',\n",
    "                  'microalbuminuria',\n",
    "                  'Colesterol_total', \n",
    "                  'Colesterol_HDL', \n",
    "                  'per_abdominal', \n",
    "                  'adhiere_hta', \n",
    "                  'antihipertensivos calcioantagonistas', \n",
    "                  'medicion'], \n",
    "                 axis = 1, \n",
    "                 inplace = True)\n",
    "\n",
    "    ## Normaliando las variables \n",
    "    vars_to_norm = list(set(ml_data.columns).intersection(set(vars_to_norm)))\n",
    "    ml_data, stats_df = vars_normalize(data_mat = ml_data, \n",
    "                                           vars_to_normalize = vars_to_norm, \n",
    "                                           tgt_cat = tgt_cat,\n",
    "                                           tgt_year = tgt_year)\n",
    "        \n",
    "    all_stats_dfs.append(stats_df)\n",
    "    \n",
    "    ## Seleccionando la suma de tags \n",
    "    ml_data = tag_var_selector(data_mat = ml_data,\n",
    "                               tag_type = 'max')\n",
    "\n",
    "    ## Generando versiones short de la base de datos \n",
    "    ml_data_short = ml_data.dropna()\n",
    "\n",
    "    ## Recodificando comorbilidades y metas\n",
    "    ml_data_short = labels_transform(data_mat = ml_data_short)\n",
    "\n",
    "    ## Reorganizando los valores de creatinina\n",
    "    ml_data_short = pd.concat([ml_data_short.drop(ml_data_short.filter(like = 'creatinina').columns, \n",
    "                                                  axis = 1),\n",
    "                               ml_data_short.loc[:, ['creatinina', 'creatinina_missing']]],\n",
    "                              axis = 1)\n",
    "\n",
    "    ## Guardando cada horizonte temporal\n",
    "    ml_data_short.to_csv(created_path+\"ml_databases/{}_cat/masters/master_db_{}_years.csv\".format(tgt_cat, tgt_year), index = False)\n",
    "    \n",
    "all_stats_df = pd.concat(all_stats_dfs, \n",
    "                        axis = 0).loc[:, ['cat_levels',\n",
    "                                          'years', \n",
    "                                          'index', \n",
    "                                          'mean', \n",
    "                                          'sd']].rename({'index' : 'variable'}, \n",
    "                                                        axis = 1)\n",
    "all_stats_df.to_csv(created_path+'ml_vars_normalization_stats.csv', index = False)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0df07",
   "metadata": {},
   "source": [
    "## Procesamiento individual de cada estadio base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30039907",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Listado de variables categóricas y numéricas\n",
    "categorical_vars = ['femenino', 'ERC_high', 'ERC1', 'ERC2', 'adhiere_guia', 'no_adhiere', 'adhiere_colesterol', 'analgesicos',\n",
    "                   'antiacidos', 'antihipertensivos', 'hipoglicemiantes', 'hipolipemiantes', 'nutrition_tag_max', \n",
    "                   'exercise_tag_max', 'alcohol_tag_max', 'tobaco_tag_max', 'creatinina_missing']\n",
    "\n",
    "numerical_vars = set(ml_data_short.columns).difference(set(categorical_vars+['KeyAnonimo', 'year', 'base_label', 'comorbilidades', 'fuera_metas', 'tgt_label']))\n",
    "numerical_vars = list(numerical_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67e732d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_cat = 4\n",
    "\n",
    "## Iterando entre los horizontes temporales de predicción\n",
    "for tgt_year in [1, 2]:\n",
    "\n",
    "    ## Cargando el master \n",
    "    master = pd.read_csv(created_path+\"ml_databases/{}_cat/masters/master_db_{}_years.csv\".format(tgt_cat, tgt_year))\n",
    "\n",
    "    ## Iterando entre las etiquetas base\n",
    "    for base_label in [1, 2, 3, 4]:\n",
    "        sub_master = master[master['base_label'] == base_label]\n",
    "\n",
    "        ## Elminando columnas no representativas entre las variables categóricas\n",
    "        for var in categorical_vars:\n",
    "            if len(sub_master.value_counts(var)) == 1:\n",
    "                sub_master.drop(var, axis = 1, inplace = True)\n",
    "\n",
    "        ## Partición entre training y validation\n",
    "        train, vali = db_partitioning(data_mat = sub_master,\n",
    "                                      base_label = base_label,\n",
    "                                      train_proportion = 0.7)\n",
    "\n",
    "        ## Guardando los archivos\n",
    "        train.to_csv(created_path+\"ml_databases/{}_cat/train/train_db_{}_years_base_{}.csv\".format(tgt_cat, tgt_year, base_label), index = False)\n",
    "        vali.to_csv(created_path+\"ml_databases/{}_cat/vali/vali_db_{}_years_base_{}.csv\".format(tgt_cat, tgt_year, base_label), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
